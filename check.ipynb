{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取聚类结果\n",
    "cluster = pd.read_csv('./labels/JODIE/wikipedia/cluster_labels.csv')\n",
    "\n",
    "# 提取每个节点的最后一个时刻标签\n",
    "last_indices_cluster = cluster.groupby('src_node_ids')['timestamps'].idxmax()\n",
    "last_labels_cluster = cluster.loc[last_indices_cluster]\n",
    "\n",
    "# 读取真实标签\n",
    "true_labels = pd.read_csv('./processed_data/wikipedia/ml_wikipedia.csv')\n",
    "\n",
    "# 提取每个节点的最后一个时刻的真实标签\n",
    "last_indices_true = true_labels.groupby('u')['ts'].idxmax()\n",
    "true_last_labels = true_labels.loc[last_indices_true]\n",
    "\n",
    "# 设置索引以便于匹配\n",
    "last_labels_cluster.set_index('src_node_ids', inplace=True)\n",
    "true_last_labels.set_index('u', inplace=True)\n",
    "\n",
    "# 替换聚类结果中的最后一个时刻的标签为真实标签\n",
    "cluster.set_index('src_node_ids', inplace=True)\n",
    "cluster.loc[last_labels_cluster.index, 'labels'] = true_last_labels['label']\n",
    "\n",
    "# 重置索引\n",
    "cluster.reset_index(inplace=True)\n",
    "\n",
    "# 保存修改后的聚类结果\n",
    "cluster.to_csv('./labels/JODIE/wikipedia/cluster_labels_with_true_last_labels.csv', index=False)\n",
    "\n",
    "# 计算准确率\n",
    "# 提取最后时刻的标签以进行比较\n",
    "last_labels_check = cluster.loc[last_indices_cluster]\n",
    "\n",
    "# 确保索引对齐\n",
    "last_labels_check.set_index('src_node_ids', inplace=True)\n",
    "\n",
    "# 计算准确率\n",
    "correct_predictions = (true_last_labels['label'] == last_labels_check['labels']).sum()\n",
    "accuracy = correct_predictions / len(true_last_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1        87.0\n",
       "Unnamed: 0          87.0\n",
       "u                   33.0\n",
       "i                 8260.0\n",
       "ts                2053.0\n",
       "label                0.0\n",
       "idx                 88.0\n",
       "last_timestamp    2053.0\n",
       "Name: 87, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_wiki = pd.read_csv('./processed_data/rt_wiki/ml_rt_wiki.csv')\n",
    "ml_wiki.iloc[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = (ml_wiki['u'] == cluster['src_node_ids']).sum()\n",
    "accuracy = correct_predictions / len(ml_wiki)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_wiki['label'] = cluster['labels'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1        87.0\n",
       "Unnamed: 0          87.0\n",
       "u                   33.0\n",
       "i                 8260.0\n",
       "ts                2053.0\n",
       "label                1.0\n",
       "idx                 88.0\n",
       "last_timestamp    2053.0\n",
       "Name: 87, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_wiki.iloc[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_wiki.to_csv('./processed_data/rt_wiki/ml_rt_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.3631e-44,  6.8589e+22, -5.3770e-17,  ...,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00], device='cuda:2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(10000).to('cuda:2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataset spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_raw_features.shape: (10985, 172)\n",
      "The feature matrix is entirely zero.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "dataset_name = 'reddit'\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "\n",
    "NODE_FEAT_DIM = EDGE_FEAT_DIM = 172\n",
    "graph_df = pd.read_csv('./processed_data/{}/ml_{}.csv'.format(dataset_name, dataset_name))\n",
    "edge_raw_features = np.load('./processed_data/{}/ml_{}.npy'.format(dataset_name, dataset_name))\n",
    "node_raw_features = np.load('./processed_data/{}/ml_{}_node.npy'.format(dataset_name, dataset_name))\n",
    "print(f'node_raw_features.shape: {node_raw_features.shape}')\n",
    "if np.all(node_raw_features == 0):\n",
    "    print(\"The feature matrix is entirely zero.\")\n",
    "else:\n",
    "    print(\"The feature matrix is not entirely zero.\")\n",
    "assert NODE_FEAT_DIM >= node_raw_features.shape[1], f'Node feature dimension in dataset {dataset_name} is bigger than {NODE_FEAT_DIM}!'\n",
    "assert EDGE_FEAT_DIM >= edge_raw_features.shape[1], f'Edge feature dimension in dataset {dataset_name} is bigger than {EDGE_FEAT_DIM}!'\n",
    "# padding the features of edges and nodes to the same dimension (172 for all the datasets)\n",
    "if node_raw_features.shape[1] < NODE_FEAT_DIM:\n",
    "    node_zero_padding = np.zeros((node_raw_features.shape[0], NODE_FEAT_DIM - node_raw_features.shape[1]))\n",
    "    node_raw_features = np.concatenate([node_raw_features, node_zero_padding], axis=1)\n",
    "if edge_raw_features.shape[1] < EDGE_FEAT_DIM:\n",
    "    edge_zero_padding = np.zeros((edge_raw_features.shape[0], EDGE_FEAT_DIM - edge_raw_features.shape[1]))\n",
    "    edge_raw_features = np.concatenate([edge_raw_features, edge_zero_padding], axis=1)\n",
    "\n",
    "assert NODE_FEAT_DIM == node_raw_features.shape[1] and EDGE_FEAT_DIM == edge_raw_features.shape[1], 'Unaligned feature dimensions after feature padding!'\n",
    "\n",
    "# get the timestamp of validate and test set\n",
    "val_time, test_time = list(np.quantile(graph_df.ts, [(1 - val_ratio - test_ratio), (1 - test_ratio)]))\n",
    "\n",
    "src_node_ids = graph_df.u.values.astype(np.longlong)\n",
    "dst_node_ids = graph_df.i.values.astype(np.longlong)\n",
    "node_interact_times = graph_df.ts.values.astype(np.float64)\n",
    "edge_ids = graph_df.idx.values.astype(np.longlong)\n",
    "if dataset_name=='bot' or dataset_name=='bot22':\n",
    "    label1 = graph_df.label1.values\n",
    "    label2 = graph_df.label2.values\n",
    "    labels=[label1,label2]\n",
    "else:\n",
    "    labels=graph_df.label.values\n",
    "    labels_time = graph_df.last_timestamp.values\n",
    "# The setting of seed follows previous works\n",
    "random.seed(2020)\n",
    "\n",
    "train_mask = node_interact_times <= val_time\n",
    "val_mask = np.logical_and(node_interact_times <= test_time, node_interact_times > val_time)\n",
    "test_mask = node_interact_times > test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = labels[node_interact_times == labels_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt = labels[train_mask][node_interact_times[train_mask] == labels_time[train_mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gt = labels[val_mask][node_interact_times[val_mask] == labels_time[val_mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt = labels[test_mask][node_interact_times[test_mask] == labels_time[test_mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trian 共包含: 470713\n",
      "trian 共包含gt: 657\n",
      "train 中 gt 的占比: 0.001395754950468757\n",
      "train gt中class 1 的占比: 0.289193302891933\n",
      "\n",
      "valid 共包含: 100867\n",
      "valid 共包含gt: 687\n",
      "valid 中 gt 的占比: 0.006810949071549665\n",
      "valid gt中class 1 的占比:0.11935953420669577 \n",
      "\n",
      "test 共包含: 100867\n",
      "test 共包含gt: 8656\n",
      "test 中 gt 的占比: 0.0858159754924802\n",
      "test gt中class 1 的占比:0.010859519408502773\n"
     ]
    }
   ],
   "source": [
    "print(f'trian 共包含: {len(node_interact_times[train_mask])}')\n",
    "print(f'trian 共包含gt: {len(train_gt)}')\n",
    "print(f'train 中 gt 的占比: {len(train_gt)/len(node_interact_times[train_mask])}')\n",
    "print(f'train gt中class 1 的占比: {train_gt.sum()/len(train_gt)}\\n')\n",
    "        \n",
    "print(f'valid 共包含: {len(node_interact_times[val_mask])}')        \n",
    "print(f'valid 共包含gt: {len(valid_gt)}')        \n",
    "print(f'valid 中 gt 的占比: {len(valid_gt)/len(node_interact_times[val_mask])}')\n",
    "print(f'valid gt中class 1 的占比:{valid_gt.sum()/len(valid_gt)} \\n')\n",
    "\n",
    "print(f'test 共包含: {len(node_interact_times[test_mask])}')\n",
    "print(f'test 共包含gt: {len(test_gt)}')\n",
    "print(f'test 中 gt 的占比: {len(test_gt)/len(node_interact_times[test_mask])}')\n",
    "print(f'test gt中class 1 的占比:{test_gt.sum()/len(test_gt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_raw_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "\n",
    "def load_src_embeddings(embedding_folder):\n",
    "    src_embeddings = []\n",
    "    timestamps = []\n",
    "    src_node_ids = []\n",
    "\n",
    "    # 获取文件列表并按文件名排序\n",
    "    file_list = sorted([f for f in os.listdir(embedding_folder) if f.endswith('.pt')],\n",
    "                       key=lambda x: float(re.search(r'embeddings_(\\d+\\.?\\d*)', x).group(1)))\n",
    "\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(embedding_folder, file_name)\n",
    "        data = torch.load(file_path)\n",
    "        src_embeddings.append(data['src_node_embeddings'].numpy())\n",
    "        timestamps.append(data['timestamps'])\n",
    "        src_node_ids.append(data['src_node_ids'])\n",
    "\n",
    "    src_embeddings = np.concatenate(src_embeddings, axis=0)\n",
    "    timestamps = np.concatenate(timestamps, axis=0)\n",
    "    src_node_ids = np.concatenate(src_node_ids, axis=0)\n",
    "\n",
    "    return src_embeddings, timestamps, src_node_ids\n",
    "\n",
    "embedding_folder = './embeddings/JODIE/wikipedia/'\n",
    "save_path = './labels/JODIE/wikipedia/cluster_labels.csv'\n",
    "\n",
    "# 读取数据\n",
    "src_embeddings, timestamps, src_node_ids = load_src_embeddings(embedding_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src_embeddings = src_embeddings[train_mask]\n",
    "valid_src_embeddings = src_embeddings[val_mask]\n",
    "test_src_embeddings = src_embeddings[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Embeddings Statistics:\n",
      "Mean: -3.03743839263916\n",
      "Std: 129.05203247070312\n",
      "Min: -630.0359497070312\n",
      "Max: 628.6611328125\n",
      "Shape: (110232, 172)\n",
      "\n",
      "Validation Embeddings Statistics:\n",
      "Mean: -5.34822416305542\n",
      "Std: 149.9070587158203\n",
      "Min: -727.5516357421875\n",
      "Max: 724.584228515625\n",
      "Shape: (23621, 172)\n",
      "\n",
      "Test Embeddings Statistics:\n",
      "Mean: -5.715201377868652\n",
      "Std: 161.79066467285156\n",
      "Min: -832.5928955078125\n",
      "Max: 846.3356323242188\n",
      "Shape: (23621, 172)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_statistics(name, embeddings):\n",
    "    print(f\"{name} Statistics:\")\n",
    "    means = np.mean(embeddings, axis=0).sum()\n",
    "    stds = np.std(embeddings, axis=0).sum()\n",
    "    mins = np.min(embeddings, axis=0).sum()\n",
    "    maxs = np.max(embeddings, axis=0).sum()\n",
    "    print(f\"Mean: {means}\")\n",
    "    print(f\"Std: {stds}\")\n",
    "    print(f\"Min: {mins}\")\n",
    "    print(f\"Max: {maxs}\")\n",
    "    print(f\"Shape: {embeddings.shape}\")\n",
    "    print()\n",
    "\n",
    "# 打印统计信息\n",
    "print_statistics(\"Train Embeddings\", train_src_embeddings)\n",
    "print_statistics(\"Validation Embeddings\", valid_src_embeddings)\n",
    "print_statistics(\"Test Embeddings\", test_src_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "val_labels = torch.load('./some_data/val_labels.pt')\n",
    "val_preds = torch.load('./some_data/val_predicts.pt')\n",
    "test_labels = torch.load('./some_data/test_labels.pt')\n",
    "test_preds = torch.load('./some_data/test_predicts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9836065573770492"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "binary_predicts = (val_preds.cpu().numpy() >= 0.5).astype(int)  \n",
    "accuracy = accuracy_score(y_true=val_labels.cpu().numpy(), y_pred=binary_predicts)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_predicts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predicts = (test_preds.cpu().numpy() >= 0.5).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_predicts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class inst():\n",
    "    def __init__(self):\n",
    "        self.val = torch.tensor([0,1,2])\n",
    "a = inst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(item):\n",
    "    model = item.val\n",
    "    model = torch.tensor([2,3,4])\n",
    "    print(item.val)\n",
    "func(a)\n",
    "a.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788]])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from utils.DataLoader import Data\n",
    "\n",
    "\n",
    "def set_random_seed(seed: int = 0):\n",
    "    \"\"\"\n",
    "    set random seed\n",
    "    :param seed: int, random seed\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed(0)\n",
    "a = torch.randn(1, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
